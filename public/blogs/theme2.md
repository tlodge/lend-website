
In our most recent Lived Experience Advisory Panel workshop we presented a very early stage prototype to seed discussions about the features of our intervention. They were asked to use our prototype to ‘bookmark’ up to four narratives that they felt were valuable. They were also asked to try two different approaches to find narratives:

i. *structured browsing* which displayed thumbnails of videos alongside titles and summaries, with simple filters to refine the list of available videos and 
ii. *a conversational interface* that provides clips from narratives in response to discussions.   

## Richness of requirements and 'co-identification'

This small exercise confirmed something important: there is a rich range of features that users may desire from their narratives: information, shared experiences, cultural resonance, advice. For shared-experience narratives, the 'shared' part is equally rich: gender, relationship roles, dementia type and stage as well as specific situations and circumstances. 

How effectively we manage this may significantly impact on the outcomes of the intervention. Moreover, our discussions around [narrative harms](./theme3) indicate that there may be a risk of causing harm (frustration, distress, feelings of exclusion) if the narratives fail to meet often quite specific intentions. 

We'd like to understand whether conversational interfaces are able to help capture this richness. From our (very early) observations, users won't necessarily come to the intervention with a clear understanding of what they need. If this is true, then providing an extensive set of search filters or even rich search functionality won't help them much. Perhaps a process of 'co-identification' where users converse with an agent to gradually establish their need, might turn out to be more effective. The richness of the discussions we observed when our LEAP members used the chat prototype would suggest so.

## Scaffolding the narrative lifecycle 

We have tended to view a narrative intervention as a two-stage process; discovery and delivery (with perhaps basic feedback at the end). However we also noticed, with the conversational interface, that some participants chose to discuss narratives that they'd already watched. This may be quite significant. Can and should we do more to support reflection on a narrative?  Might this amplify the benefits? Might it help provide better recommendations? Here are a few hypotheses we'd like to explore further:

- Structured reflection may amplify benefits.
- Post-narrative discussion may yield richer, more nuanced feedback.
- Referencing previously viewed narratives may help users articulate complex or hard-to-express needs.

## The ambiguous role of conversational agents

We've discussed how conversation agents may offer a promising way to identify effective and appropriate narratives.  But there are big challenges. For example, we observed ambiguity about the AI chatbot’s role. Our chatbot's open-ended interactions (i.e. answering user messages with follow-up questions) sometimes elicited personal disclosures and expectations of emotional support. This immediately raises safeguarding concerns. If users expect conversations to address unmet emotional needs, systems must provide validated specialist support.  

For now, we're cautiously interested and keen to dig a little deeper.  Although conversational co-identification of narratives shows potential, it has to be designed with attention to personalisation, cultural sensitivity, and user safety, alongside full transparency about AI’s role and limitations. We have to ask, will this be enough? 

We have submitted an abstract for a poster that summarises some of these early observations to the University of Nottingham's Dementia Showcase.  We'll link to it here if our submission is successful.

